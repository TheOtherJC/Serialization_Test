{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autotime extension is already loaded. To reload it, use:\n",
      "  %reload_ext autotime\n",
      "time: 4.93 ms\n"
     ]
    }
   ],
   "source": [
    "%load_ext autotime\n",
    "import numpy as np\n",
    "import msgpack\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \"Interchange Dictionary\" (InterDict) concept-test implementation\n",
    "\n",
    "\n",
    "* This is a specialized container that representing a dictionary of dictionaries.\n",
    "* Everything is written (transactionally) to on-disk storage\n",
    "* Obvious goal is to provide key-value database of serialized dicts that, when stored on a shared filesystem, allows concurrent access from multiple processes/hosts\n",
    "* Global write lock; reads do not lock\n",
    "* Unique sets of keys for the stored dictionaries are hashed (this saves disk space; hurts performance, probably not necessary)\n",
    "* Pure python, could probably be sped up by using cythonized functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 169 ms\n"
     ]
    }
   ],
   "source": [
    "import lmdb, msgpack, hashlib\n",
    "from pyhashxx import hashxx\n",
    "\n",
    "class InterDict(object):\n",
    "\n",
    "    def unpack(self, v):\n",
    "        return msgpack.unpackb(v)\n",
    "\n",
    "    def pack(self, v):\n",
    "        return msgpack.packb(v)\n",
    "\n",
    "    def hash(self, v):\n",
    "        return np.uint64(hashxx(v, seed=0))\n",
    "\n",
    "    def __init__(self, dbdir):\n",
    "        self.dbdir = dbdir if isinstance(dbdir, bytes) else dbdir.encode()\n",
    "        self.env = lmdb.open(dbdir, max_dbs=3, map_size=int(1e9))\n",
    "        self.hashes = self.env.open_db(b'hashes', integerkey=True)\n",
    "        self.keys = self.env.open_db(b'keys', integerkey=True)\n",
    "        self.vals = self.env.open_db(b'vals', integerkey=True)\n",
    "\n",
    "    def __setitem__(self, key, val):\n",
    "        key_packed = np.uint64(key)\n",
    "        dk = tuple(sorted(val.keys()))\n",
    "        dk_packed = self.pack(dk)\n",
    "        dk_hashed = self.hash(dk_packed)\n",
    "        dv = tuple(val[k] for k in dk)\n",
    "        dv_packed = self.pack(dv)\n",
    "        with self.env.begin(write=True, buffers=True) as txn:\n",
    "            txn.put(dk_hashed, dk_packed, db=self.hashes)\n",
    "            txn.put(key_packed, dk_hashed, db=self.keys)\n",
    "            txn.put(key_packed, dv_packed, db=self.vals)\n",
    "\n",
    "    def __getitem__(self, key):\n",
    "        key_packed = np.uint64(key)\n",
    "        with self.env.begin(write=False, buffers=True) as txn:\n",
    "            dk_hashed = txn.get(key_packed, db=self.keys)\n",
    "            if dk_hashed is not None:\n",
    "                dk_packed = txn.get(dk_hashed, db=self.hashes)\n",
    "                if dk_packed is not None:\n",
    "                    dk = self.unpack(dk_packed)\n",
    "                else:\n",
    "                    raise KeyError()\n",
    "            else:\n",
    "                raise KeyError()\n",
    "            dv_packed = txn.get(key_packed, db=self.vals)\n",
    "            if dv_packed is not None:\n",
    "                dv = self.unpack(dv_packed)\n",
    "            else:\n",
    "                raise KeyError()\n",
    "        return dict(zip(dk,dv))\n",
    "\n",
    "    def batch_inserter(self, dict_keys):\n",
    "        dk = tuple(sorted(dict_keys))\n",
    "        dk_packed = self.pack(dk)\n",
    "        dk_hashed = self.hash(dk_packed)\n",
    "\n",
    "        with self.env.begin(write=True) as txn:\n",
    "            txn.put(dk_hashed, dk_packed, db=self.hashes)\n",
    "\n",
    "        def inserter_function(itr):\n",
    "            with self.env.begin(write=True) as txn:\n",
    "                for key,val in itr:\n",
    "                    key_packed = np.uint64(key)\n",
    "                    dv = tuple(val[k] for k in dk)\n",
    "                    dv_packed = self.pack(dv)    \n",
    "                    txn.put(key_packed, dk_hashed, db=self.keys)\n",
    "                    txn.put(key_packed, dv_packed, db=self.vals)\n",
    "\n",
    "        return inserter_function\n",
    "    \n",
    "    def batch_getvalues(self, dict_keys):\n",
    "        dk = tuple(sorted(dict_keys))\n",
    "        dk_packed = self.pack(dk)\n",
    "        dk_hashed = self.hash(dk_packed)\n",
    "\n",
    "        def getvalues_function(itr):\n",
    "            with self.env.begin(write=False) as txn:\n",
    "                for key in itr:\n",
    "                    key_packed = np.uint64(key)\n",
    "                    if dk_hashed == np.frombuffer(txn.get(key_packed, db=self.keys),\n",
    "                                                  dtype='uint64')[0]:\n",
    "                        dv_packed = txn.get(key_packed, db=self.vals)\n",
    "                        if dv_packed is not None:\n",
    "                            yield self.unpack(dv_packed)\n",
    "                        else:\n",
    "                            raise KeyError()\n",
    "                    else:\n",
    "                        raise KeyError()\n",
    "                        \n",
    "        return getvalues_function\n",
    "                    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple performance comparisons\n",
    "\n",
    "Compares serialization and deserialization times to:\n",
    "\n",
    "* a plain python dictionary\n",
    "* a python dictionary of msgpack serialialized dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 146 ms\n"
     ]
    }
   ],
   "source": [
    "ndicts = 10000\n",
    "nkeys = 10\n",
    "test_dict = {}\n",
    "test_msgpack = {}\n",
    "dummy = None\n",
    "!rm -r '/tmp/test-interdict'\n",
    "interd = InterDict('/tmp/test-interdict')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plain python dict storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 232 ms\n"
     ]
    }
   ],
   "source": [
    "for i in range(ndicts):\n",
    "    test_dict[i] = {j:str(random.random()) for j in range(nkeys)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dict storing msgpack bytestrings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 292 ms\n"
     ]
    }
   ],
   "source": [
    "for i in range(ndicts):\n",
    "    test_msgpack[i] = msgpack.packb({j:str(random.random()) for j in range(nkeys)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## serialized storage using the InterDict on-disk dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 5.17 s\n"
     ]
    }
   ],
   "source": [
    "for i in range(ndicts):\n",
    "    interd[i] = {j:str(random.random()) for j in range(nkeys)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## batch insertion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 427 ms\n"
     ]
    }
   ],
   "source": [
    "batch_inserter = interd.batch_inserter([i for i in range(nkeys)])\n",
    "def itr(ndicts, nkeys):\n",
    "    for i in range(ndicts):\n",
    "        yield (i, tuple(str(random.random()) for j in range(nkeys)))\n",
    "batch_inserter(itr(ndicts, nkeys))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deserialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plain python dict (random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 50 ms\n"
     ]
    }
   ],
   "source": [
    "for n in range(ndicts):\n",
    "    i = random.randint(0, ndicts-1)\n",
    "    dummy = test_dict[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## msgpack dict (random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 87.6 ms\n"
     ]
    }
   ],
   "source": [
    "for n in range(ndicts):\n",
    "    i = random.randint(0, ndicts-1)\n",
    "    dummy = msgpack.unpackb(test_msgpack[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## InterDict (random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 256 ms\n"
     ]
    }
   ],
   "source": [
    "for n in range(ndicts):\n",
    "    i = random.randint(0, ndicts-1)\n",
    "    dummy = interd[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## InterDict (sequential)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 203 ms\n"
     ]
    }
   ],
   "source": [
    "for n in range(ndicts):\n",
    "    dummy = interd[n]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## InterDict batch access (random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 226 ms\n"
     ]
    }
   ],
   "source": [
    "batch_getvalues = interd.batch_getvalues(tuple(i for i in range(nkeys)))\n",
    "def random_idx(ndicts):\n",
    "    for i in range(ndicts):\n",
    "        yield random.randint(0, ndicts-1)\n",
    "for x in batch_getvalues(random_idx(ndicts)):\n",
    "    dummy = x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## InterDict batch access (sequential)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 172 ms\n"
     ]
    }
   ],
   "source": [
    "batch_getvalues = interd.batch_getvalues(tuple(i for i in range(nkeys)))\n",
    "for x in batch_getvalues(range(ndicts)):\n",
    "    dummy = x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "abm_dev",
   "language": "python",
   "name": "abm_dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
